# ObjectBox Architecture in Neural-Studio

> **Living Document:** Maps ObjectBox stores to our actual codebase architecture

---

## Architectural Hierarchy

```
Profile (gaming, podcast, etc.)
    â†“
Manager (AudioManager, VideoManager, GraphicsManager, etc.)
    â†“
NodeType (Audio, Video, Graphics - broader category)
    â†“
Node Variant (AudioClip, AudioStreamMusic, VideoCa pture - specific implementation)
    â†“
Pipeline Schema (connection topology for source nodes)
```

### Example: Complete Flow

```
Profile: "gaming"
â”œâ”€â”€ AudioManager
â”‚   â”œâ”€â”€ NodeType: "Audio"
â”‚   â”‚   â”œâ”€â”€ Variant: AudioClip â†’ node_abc123
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioClipSettings.fbs
â”‚   â”‚   â”‚   â””â”€â”€ AudioClipPipeline.fbs (source node!)
â”‚   â”‚   â”œâ”€â”€ Variant: AudioClipFX â†’ node_def456
â”‚   â”‚   â”‚   â””â”€â”€ AudioClipFXSettings.fbs (no pipeline - not source)
â”‚   â”‚   â””â”€â”€ Variant: AudioStreamMusic â†’ node_ghi789
â”‚   â”‚       â”œâ”€â”€ AudioStreamMusicSettings.fbs
â”‚   â”‚       â””â”€â”€ AudioStreamMusicPipeline.fbs (source node!)
â”‚   â”‚
â”œâ”€â”€ VideoManager
â”‚   â”œâ”€â”€ NodeType: "Video"
â”‚   â”‚   â”œâ”€â”€ Variant: VideoCapture â†’ node_jkl012
â”‚   â”‚   â”‚   â”œâ”€â”€ VideoCaptureSettings.fbs
â”‚   â”‚   â”‚   â””â”€â”€ VideoCapturePipeline.fbs
â”‚   â”‚   â””â”€â”€ Variant: VideoFile â†’ node_mno345
â”‚   â”‚       â”œâ”€â”€ VideoFileSettings.fbs
â”‚   â”‚       â””â”€â”€ VideoFilePipeline.fbs
â”‚   â”‚
â””â”€â”€ EffectsManager
    â”œâ”€â”€ NodeType: "Effects"
    â”‚   â”œâ”€â”€ Variant: ColorCorrection â†’ node_pqr678
    â”‚   â”‚   â””â”€â”€ ColorCorrectionSettings.fbs (never source - no pipeline)
    â”‚   â””â”€â”€ Variant: ChromaKey â†’ node_stu901
    â”‚       â””â”€â”€ ChromaKeySettings.fbs (never source - no pipeline)
```

**Key Insight:** 
- **Profile** = User workspace boundary
- **Manager** = UI category (which panel launches nodes)
- **NodeType** = Logical grouping in Master Store
- **Node Variant** = Specific implementation with unique schema
- **Pipeline Schema** = Auto-created for source nodes (no inputs)

---

## The Four-Store System

### 1. Master Store (Global - Singleton)
**Location:** `~/.config/neural-studio/objectbox/master/`  
**Lifecycle:** Created once on install, read-only

#### Entities

**NodeType** - Base node type definitions
- Example: "AudioNode", "VideoNode", "GraphicsNode"
- Used by: All managers as base category

**NodeVariant** - Specific variant within a node type
- Example: "AudioClip", "AudioStreamMusic", "VideoCapture"
- Links to: NodeType (parent)
- Defines: Default config, ports, widgets

**ConnectionRule** - Valid connection types between variants
- Example: AudioClip.output â†’ AudioClipFX.input
- Validates: Port types, data flow

**PipelineTemplate** - Pre-built workflows
- Example: "Podcast Setup" (AudioStream â†’ AudioClipFX â†’ Output)

#### Schema Files (Master)
```
schemas/master/
â”œâ”€â”€ NodeType.fbs          # AudioNode, VideoNode, etc.
â”œâ”€â”€ NodeVariant.fbs       # AudioClip, AudioStreamMusic, etc.
â”œâ”€â”€ ConnectionRule.fbs    # Valid connections
â””â”€â”€ PipelineTemplate.fbs  # Workflow templates
```

---

### 2. Profile Store (Per-User-Profile)
**Location:** `~/Neural-Studio/profiles/<profile_name>/objectbox/`  
**Lifecycle:** Created per profile, active while profile loaded

**THIS IS THE REGISTRY - NOT NODE DATA**

#### Entities

**GraphNode** - Node instances in blueprint
- Links to: NodeVariant (master) + Node Store UUID
- Stores: Position (x, y), name, enabled state
- Example: `{id: 1, variant_id: AudioClip, uuid: node_abc123, pos_x: 100}`

**GraphEdge** - Connections between nodes
- Relations: from_node_id, to_node_id (â†’ GraphNode)
- Stores: Port names, data type
- Example: `{from: node_abc123.output, to: node_def456.input}`

**BroadcastSettings** - Streaming configs
- Per profile, not per node
- Used by: StreamingManager

**SceneObject** - 3D scene objects
- Links to: GraphNode (which node controls this object)
- Syncs with: USD Stage in ActiveFrame

**AnimationKeyframe** - Timeline animations
- Time-series with id-companion
- Links to: SceneObject

#### Schema Files (Profile)
```
schemas/profile/
â”œâ”€â”€ GraphNode.fbs
â”œâ”€â”€ GraphEdge.fbs
â”œâ”€â”€ BroadcastSettings.fbs
â”œâ”€â”€ SceneObject.fbs
â””â”€â”€ AnimationKeyframe.fbs
```

---

### 3. Node Variant Stores (Per-Instance!)
**Location:** `~/Neural-Studio/profiles/<profile>/nodes/<node_uuid>/objectbox/`  
**Lifecycle:** Created when variant instantiated, deleted when removed

**THIS IS WHERE ACTUAL NODE DATA LIVES**

#### Per-Variant Schema Structure

Each variant instance needs **2 schemas minimum**:
1. **Settings Schema** - Always present
2. **Pipeline Schema** - Only if source node (no incoming connections)

#### Example: AudioManager Variants (8 total)

##### AudioClip Variant
```
Node Store: node_abc123/objectbox/

Schemas:
â”œâ”€â”€ AudioClipSettings.fbs
â”‚   â”œâ”€â”€ clip_path: string
â”‚   â”œâ”€â”€ start_time_ms: long
â”‚   â”œâ”€â”€ end_time_ms: long
â”‚   â”œâ”€â”€ volume: float
â”‚   â””â”€â”€ loop: bool
â”‚
â””â”€â”€ AudioClipPipeline.fbs (if source node!)
    â”œâ”€â”€ source_variant_id: ulong
    â”œâ”€â”€ pipeline_nodes: [ulong]  // Ordered store IDs
    â”œâ”€â”€ connection_map: string   // Simple JSON topology of store IDs (array of connections)
    â””â”€â”€ last_updated: long
```

##### AudioClipFX Variant
```
Node Store: node_def456/objectbox/

Schemas:
â”œâ”€â”€ AudioClipFXSettings.fbs
â”‚   â”œâ”€â”€ fx_type: string          // reverb, eq, compressor
â”‚   â”œâ”€â”€ parameters: string       // JSON config
â”‚   â”œâ”€â”€ wet_dry: float
â”‚   â””â”€â”€ bypass: bool
â”‚
â””â”€â”€ (No pipeline - not a source)
```

##### AudioStreamMusic Variant
```
Node Store: node_ghi789/objectbox/

Schemas:
â”œâ”€â”€ AudioStreamMusicSettings.fbs
â”‚   â”œâ”€â”€ stream_url: string
â”‚   â”œâ”€â”€ codec: string
â”‚   â”œâ”€â”€ sample_rate: int
â”‚   â”œâ”€â”€ buffer_size: int
â”‚   â””â”€â”€ reconnect: bool
â”‚
â””â”€â”€ AudioStreamMusicPipeline.fbs (if source!)
    â”œâ”€â”€ source_variant_id: ulong
    â”œâ”€â”€ pipeline_nodes: [ulong]
    â”œâ”€â”€ connection_map: string
    â””â”€â”€ last_updated: long
```

#### Complete AudioManager Variant Schemas

```
schemas/nodes/audio/
â”œâ”€â”€ AudioClipSettings.fbs
â”œâ”€â”€ AudioClipPipeline.fbs
â”œâ”€â”€ AudioClipFXSettings.fbs
â”œâ”€â”€ AudioClipMusicSettings.fbs
â”œâ”€â”€ AudioClipMusicPipeline.fbs
â”œâ”€â”€ AudioClipPodcastSettings.fbs
â”œâ”€â”€ AudioClipPodcastPipeline.fbs
â”œâ”€â”€ AudioStreamSettings.fbs
â”œâ”€â”€ AudioStreamPipeline.fbs
â”œâ”€â”€ AudioStreamMusicSettings.fbs
â”œâ”€â”€ AudioStreamMusicPipeline.fbs
â”œâ”€â”€ AudioStreamPodcastSettings.fbs
â”œâ”€â”€ AudioStreamPodcastPipeline.fbs
â”œâ”€â”€ AudioStreamVoiceCallSettings.fbs
â””â”€â”€ AudioStreamVoiceCallPipeline.fbs
```

#### Other Manager Variants (Future)

**VideoManager** - Variants might include:
- VideoCapture, VideoFile, VideoStream, VideoScreenCapture, VideoNDI, etc.

**GraphicsManager** - Variants might include:
- ImageStatic, ImageSequence, GraphicsOverlay, GraphicsParticles, etc.

**EffectsManager** - Variants might include:
- ColorCorrection, ChromaKey, Blur, Transform, etc.

---

### 4. AI Memory Store (Global - Learning)
**Location:** `~/.config/neural-studio/objectbox/ai_memory/`  
**Lifecycle:** Persistent, grows over time

#### Entities

**GraphEvent** - User action log (time-series)
- Logs: Every node add/delete/connect
- Stores: variant type, context hash, session

**GraphPattern** - Learned workflows
- Example: "AudioStream â†’ AudioClipFX â†’ Output" (frequency: 42)
- Unique: pattern_hash

**IntentPrediction** - AI suggestions
- Context â†’ next likely variant
- Confidence scores

#### Schema Files (AI)
```
schemas/ai/
â”œâ”€â”€ GraphEvent.fbs
â”œâ”€â”€ GraphPattern.fbs
â””â”€â”€ IntentPrediction.fbs
```

---

## Pipeline Schema Logic

### What is a Source Node?

**Definition:** A node with **NO incoming connections** (no edges on top/left input side)

```
âœ… Source Nodes (create pipeline schema):
AudioStream â”€â”€â†’ (no input)
VideoCapture â”€â”€â†’ (no input)
ImageStatic â”€â”€â†’ (no input)

âŒ Not Source Nodes (no pipeline schema):
AudioClipFX â†â”€â”€ input from AudioStream
ColorCorrection â†â”€â”€ input from VideoCapture
```

### When Pipeline Schema is Created

```
1. Node variant instantiated
   â””â”€> Check incoming edges

2. If NO incoming edges (source node):
   â””â”€> Create <VariantName>Pipeline schema

3. On every downstream connection change:
   â””â”€> Update pipeline schema with new topology
```

### Pipeline Schema Structure

```flatbuffers
table AudioClipPipeline {
    id: ulong;
    
    /// Source node reference
    source_node_uuid: string;
    source_variant_id: ulong;
    
    /// Pipeline topology (ordered)
    pipeline_nodes: [ulong];  // Array of store IDs in order
    
    /// Connection map (simple topology structure)
    /// Stores which nodes connect to which, in order
    connection_map: string;
    
    /// Branching support
    branches: string;  // JSON array of branch paths
    
    /// Side connections
    side_inputs: string;  // JSON: which nodes connect from side
    
    /// Last update timestamp
    last_updated: long;
}
```

### Connection Map Examples

**Important:** Think of the pipeline **as a diagram** visually, but what we **store is the straight relationship data**. The connections can be unpredictable and complex.

We store:
- Which nodes connect to which
- The order/topology
- Not a literal diagram format - just the data relationships

#### Simple Linear Pipeline
```json
{
  "source": "node_abc123",
  "connections": [
    {"from": "node_abc123", "to": "node_def456"},
    {"from": "node_def456", "to": "node_ghi789"}
  ]
}
```
Visualized as a diagram: `abc123 â†’ def456 â†’ ghi789`

#### Branched Pipeline
```json
{
  "source": "node_abc123",
  "connections": [
    {"from": "node_abc123", "to": "node_def456"},
    {"from": "node_abc123", "to": "node_jkl012"},
    {"from": "node_def456", "to": "node_ghi789"}
  ]
}
```
Visualized as a diagram:
```
abc123 â†’ def456 â†’ ghi789
   â””â”€â”€â†’ jkl012
```

#### Side Connections (Modulation/Control)
```json
{
  "source": "node_abc123",
  "connections": [
    {"from": "node_abc123", "to": "node_def456"},
    {"from": "node_xyz999", "to": "node_def456", "type": "modulation"}
  ]
}
```
Visualized as a diagram:
```
abc123 â†’ def456
           â†‘
        xyz999 (side input)
```

---

## Manager â†’ Variant â†’ Schema Mapping

### Current Managers (ui/shared_ui/managers/)

| Manager | Variants | Settings Schemas | Pipeline Schemas |
|---------|----------|------------------|------------------|
| **AudioManager** | 8 variants | AudioClipSettings<br>AudioClipFXSettings<br>AudioClipMusicSettings<br>AudioClipPodcastSettings<br>AudioStreamSettings<br>AudioStreamMusicSettings<br>AudioStreamPodcastSettings<br>AudioStreamVoiceCallSettings | AudioClipPipeline<br>AudioClipMusicPipeline<br>AudioClipPodcastPipeline<br>AudioStreamPipeline<br>AudioStreamMusicPipeline<br>AudioStreamPodcastPipeline<br>AudioStreamVoiceCallPipeline |
| **VideoManager** | ~5 variants | VideoFileSettings<br>VideoCaptureSettings<br>etc. | VideoFilePipeline<br>VideoCapturePipeline<br>etc. |
| **GraphicsManager** | ~4 variants | ImageStaticSettings<br>GraphicsOverlaySettings<br>etc. | ImageStaticPipeline<br>GraphicsOverlayPipeline<br>etc. |
| **CameraManager** | ~3 variants | Camera3DSettings<br>CameraOrthographicSettings<br>etc. | (Cameras usually not source) |
| **EffectsManager** | ~10 variants | ColorCorrectionSettings<br>ChromaKeySettings<br>BlurSettings<br>etc. | (Effects never source) |
| **ShaderManager** | ~5 variants | CustomShaderSettings<br>etc. | (Shaders never source) |
| **ScriptManager** | ~3 variants | LuaScriptSettings<br>PythonScriptSettings<br>etc. | (Scripts modify, not source) |
| **LLMManager** | ~2 variants | LLMGeneratorSettings<br>LLMAnalyzerSettings | LLMGeneratorPipeline(maybe) |
| **MLManager** | ~3 variants | MLInferenceSettings<br>MLTrainingSettings | MLInferencePipeline(maybe) |

---

## Data Flow: Full Example

### User Creates Audio Podcast Pipeline

```
1. User opens AudioManager panel
   â””â”€> Lists 8 available variants (from Master Store NodeVariant)

2. User drags "AudioStreamPodcast" to blueprint
   â””â”€> BlueprintFrame creates GraphNode
       â”œâ”€ Generates UUID: node_abc123
       â”œâ”€ Links to: NodeVariant(AudioStreamPodcast)
       â”œâ”€ Writes to Profile Store:
       â”‚   GraphNode {variant_id: AudioStreamPodcast, uuid: node_abc123}
       â””â”€ Creates Node Store:
           ~/profiles/podcast/nodes/node_abc123/objectbox/

3. Backend initializes node store with 2 schemas:
   â”œâ”€ AudioStreamPodcast Settings.fbs
   â”‚   â””â”€ Default values populated
   â””â”€ AudioStreamPodcastPipeline.fbs (CREATED - it's a source!)
       â””â”€ Initial state: just source node

4. User opens settings widget
   â””â”€> Binds to: node_abc123/objectbox/ AudioStreamPodcastSettings
   â””â”€> User sets: stream_url, codec, buffer_size
   â””â”€> Writes to node store

5. User adds "AudioClipFX" node
   â””â”€> UUID: node_def456
   â””â”€> Creates: AudioClipFXSettings schema only (not source)

6. User connects: AudioStreamPodcast.output â†’ AudioClipFX.input
   â””â”€> Creates GraphEdge in Profile Store
   â””â”€> **Updates AudioStreamPodcastPipeline:**
       {
         source: "node_abc123",
         nodes: ["node_def456"],
         connections: ["abc123->def456"]
       }

7. User adds "Output" node
   â””â”€> UUID: node_ghi789

8. User connects: AudioClipFX.output â†’ Output.input
   â””â”€> **Updates AudioStreamPodcastPipeline again:**
       {
         source: "node_abc123",
         nodes: ["node_def456", "node_ghi789"],
         connections: ["abc123->def456->ghi789"]
       }

9. Backend processes pipeline:
   â”œâ”€ Reads AudioStreamPodcastPipeline from node_abc123 store
   â”œâ”€ Iterates store IDs in order
   â”œâ”€ Loads each node's settings
   â”œâ”€ Builds processing chain
   â””â”€> Outputs to SceneGraph â†’ ActiveFrame
```

---

## File Structure

### Schemas Organization

```
core/src/state/schemas/
â”œâ”€â”€ master/
â”‚   â”œâ”€â”€ NodeType.fbs
â”‚   â”œâ”€â”€ NodeVariant.fbs
â”‚   â”œâ”€â”€ ConnectionRule.fbs
â”‚   â””â”€â”€ PipelineTemplate.fbs
â”‚
â”œâ”€â”€ profile/
â”‚   â”œâ”€â”€ GraphNode.fbs
â”‚   â”œâ”€â”€ GraphEdge.fbs
â”‚   â”œâ”€â”€ BroadcastSettings.fbs
â”‚   â”œâ”€â”€ SceneObject.fbs
â”‚   â””â”€â”€ AnimationKeyframe.fbs
â”‚
â”œâ”€â”€ nodes/
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ AudioClipSettings.fbs
â”‚   â”‚   â”œâ”€â”€ AudioClipPipeline.fbs
â”‚   â”‚   â”œâ”€â”€ AudioClipFXSettings.fbs
â”‚   â”‚   â”œâ”€â”€ AudioClipMusicSettings.fbs
â”‚   â”‚   â”œâ”€â”€ AudioClipMusicPipeline.fbs
â”‚   â”‚   â”œâ”€â”€ AudioClipPodcastSettings.fbs
â”‚   â”‚   â”œâ”€â”€ AudioClipPodcastPipeline.fbs
â”‚   â”‚   â”œâ”€â”€ AudioStreamSettings.fbs
â”‚   â”‚   â”œâ”€â”€ AudioStreamPipeline.fbs
â”‚   â”‚   â”œâ”€â”€ AudioStreamMusicSettings.fbs
â”‚   â”‚   â”œâ”€â”€ AudioStreamMusicPipeline.fbs
â”‚   â”‚   â”œâ”€â”€ AudioStreamPodcastSettings.fbs
â”‚   â”‚   â”œâ”€â”€ AudioStreamPodcastPipeline.fbs
â”‚   â”‚   â”œâ”€â”€ AudioStreamVoiceCallSettings.fbs
â”‚   â”‚   â””â”€â”€ AudioStreamVoiceCallPipeline.fbs
â”‚   â”‚
â”‚   â”œâ”€â”€ video/
â”‚   â”‚   â”œâ”€â”€ VideoCaptureSettings.fbs
â”‚   â”‚   â”œâ”€â”€ VideoCapturePipeline.fbs
â”‚   â”‚   â”œâ”€â”€ VideoFileSettings.fbs
â”‚   â”‚   â”œâ”€â”€ VideoFilePipeline.fbs
â”‚   â”‚   â””â”€â”€ ... (more variants)
â”‚   â”‚
â”‚   â”œâ”€â”€ graphics/
â”‚   â”œâ”€â”€ effects/
â”‚   â”œâ”€â”€ shader/
â”‚   â”œâ”€â”€ script/
â”‚   â”œâ”€â”€ llm/
â”‚   â””â”€â”€ ml/
â”‚
â””â”€â”€ ai/
    â”œâ”€â”€ GraphEvent.fbs
    â”œâ”€â”€ GraphPattern.fbs
    â””â”€â”€ IntentPrediction.fbs
```

### Project Directory Structure

```
~/Neural-Studio/profiles/podcast/
â”œâ”€â”€ objectbox/                  # Profile Store
â”‚   â””â”€â”€ data.mdb
â”‚
â””â”€â”€ nodes/                      # All node variant instances
    â”œâ”€â”€ node_abc123/           # AudioStreamPodcast instance
    â”‚   â””â”€â”€ objectbox/
    â”‚       â”œâ”€â”€ data.mdb
    â”‚       â”œâ”€â”€ AudioStreamPodcastSettings (table)
    â”‚       â””â”€â”€ AudioStreamPodcastPipeline (table)
    â”‚
    â”œâ”€â”€ node_def456/           # AudioClipFX instance
    â”‚   â””â”€â”€ objectbox/
    â”‚       â”œâ”€â”€ data.mdb
    â”‚       â””â”€â”€ AudioClipFXSettings (table)
    â”‚
    â””â”€â”€ node_ghi789/           # Output instance
        â””â”€â”€ objectbox/
            â””â”€â”€ ...
```

---

## Implementation Status

### âœ… Completed (Phase 1)
- Master Store base schemas (NodeType, ConnectionRule, PipelineTemplate)
- Profile Store schemas (GraphNode, GraphEdge, etc.)
- AI Memory Store schemas (GraphEvent, GraphPattern, IntentPrediction)
- All schemas compile successfully

### ğŸ”„ Current Phase (Phase 2)
- [ ] Add NodeVariant to Master Store
- [ ] Design node variant schemas for each manager
- [ ] Implement pipeline schema structure
- [ ] Create source node detection logic

### â³ Planned (Phase 3+)
- [ ] AudioManager: 14 schemas (8 settings + 7 pipelines - AudioClipFX not source)
- [ ] VideoManager: Variant schemas
- [ ] GraphicsManager: Variant schemas
- [ ] EffectsManager: Settings schemas (never pipeline - not source nodes)
- [ ] Pipeline auto-update on connection changes
- [ ] StoreManager coordinator with pipeline tracking

---

## Key Design Decisions

### Why Pipeline Schemas?

**Problem:** How does a source node know its entire downstream processing chain?

**Solution:** Pipeline schema maintains materialized view of full topology
- Fast lookup (no graph traversal needed)
- Easy serialization for backend processing
- Can detect circular references
- Supports branching/merging

### Why Per-Variant Stores?

**Problem:** Different variants need completely different data structures

**Solution:** Each variant = unique schema set
- AudioClip needs: file path, trim points
- AudioStream needs: URL, codec, buffer
- No shared schema bloat
- Type-safe per variant

### Why Source Node Detection?

**Problem:** Which nodes should create pipelines?

**Solution:** Auto-detect based on incoming edges
- Simple rule: no inputs = source
- Pipelines only where needed
- Saves storage

---

**Last Updated:** 2025-12-15  
**Phase:** 1 Complete, Starting Phase 2 (Variant Schemas)  
**Next:** Design AudioManager variant schemas, implement pipeline detection
